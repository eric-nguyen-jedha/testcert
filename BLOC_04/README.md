# AIA - BLOC_04 : Projet M√©t√©o üå¶Ô∏è 

## Pr√©sentation en ligne de l'int√©gralit√© du projet

üöÄ [Bloc_04 | PROJET M√âT√àO | Pr√©sentation PPT](https://docs.google.com/presentation/d/1nWi3Q9N6SFRfRQldj1ZbB49OlgcXWEltxNtJOjyxBNA/edit?usp=sharing) \
üìÅ [Bloc_04 | PROJET M√âT√àO | Backup sur GitHub](https://github.com/eric-nguyen-jedha/AIA-CERTIF/tree/main/BLOC_04)


Un projet de machine learning pour la pr√©diction m√©t√©orologique sur les grandes villes de France avec une interface Streamlit, des pipelines Airflow et une architecture Docker.

## üöÄ Vue d'ensemble

Ce projet impl√©mente un pipeline complet de machine learning pour pr√©dire les conditions m√©t√©orologiques √† Paris. Il inclut :

- **Mod√®le ML** : Classification des conditions m√©t√©o (XGBoost)
- **Interface web** : Application Streamlit avec carte interactive
- **Orchestration** : Pipelines Airflow pour l'entra√Ænement et la pr√©diction
- **MLOps** : Int√©gration MLflow pour le suivi des exp√©riences
- **Tests** : Suite de tests automatis√©s avec pytest

## üìÅ Structure du projet

```

‚îî‚îÄ‚îÄ AIRFLOW/
‚îú‚îÄ‚îÄ config/
‚îÇ ‚îî‚îÄ‚îÄ airflow.cfg # Configuration principale d'Airflow
‚îú‚îÄ‚îÄ dags/
‚îÇ ‚îú‚îÄ‚îÄ evidently_datacheck.py # DAG de validation des donn√©es avec Evidently
‚îÇ ‚îú‚îÄ‚îÄ meteo_paris.py # DAG principal pour les donn√©es m√©t√©o Paris
‚îÇ ‚îú‚îÄ‚îÄ paris_meteo_ml_pipeline.py # DAG pour le pipeline ML (entra√Ænement, etc.)
‚îÇ ‚îî‚îÄ‚îÄ realtime_prediction_forecast.py # DAG pour les pr√©dictions en temps r√©el
‚îú‚îÄ‚îÄ data/
‚îÇ ‚îú‚îÄ‚îÄ data_driftft.ipynb # Notebook d‚Äôanalyse de d√©rive des donn√©es
‚îÇ ‚îú‚îÄ‚îÄ weather_paris_drift_report.html # Rapport HTML de d√©rive
‚îÇ ‚îú‚îÄ‚îÄ weather_paris_humidity_analysis.html # Analyse d‚Äôhumidit√©
‚îÇ ‚îú‚îÄ‚îÄ weather_paris_pressure_analysis.html # Analyse de pression
‚îÇ ‚îú‚îÄ‚îÄ weather_paris_temp_analysis.html # Analyse de temp√©rature
‚îÇ ‚îú‚îÄ‚îÄ weather_paris_test_suite.html # Suite de tests HTML
‚îÇ ‚îú‚îÄ‚îÄ weather_paris_wind_speed_analysis.html # Analyse de vitesse du vent
‚îÇ ‚îî‚îÄ‚îÄ weather_paris.csv # Donn√©es brutes m√©t√©o Paris
‚îú‚îÄ‚îÄ docker-compose.yaml # Fichier de configuration Docker Compose
‚îú‚îÄ‚îÄ Dockerfile # Dockerfile pour l‚Äôenvironnement Airflow
‚îú‚îÄ‚îÄ plugins/
‚îÇ ‚îú‚îÄ‚îÄ s3_to_postgres.py # Plugin personnalis√© : transfert S3 ‚Üí PostgreSQL
‚îÇ ‚îî‚îÄ‚îÄ requirements.txt # D√©pendances sp√©cifiques aux plugins

‚îú‚îÄ‚îÄ STREAMLIT/             # Application web Streamlit
‚îú‚îÄ‚îÄ MLFLOW/                # Configuration MLflow
‚îú‚îÄ‚îÄ data/                  # Donn√©es m√©t√©o
‚îú‚îÄ‚îÄ dags_ml/ # DAGs Airflow sp√©cifiques au pipeline ML
‚îÇ ‚îú‚îÄ‚îÄ realtime_prediction_forecast.py    # Tests unitaires du pipeline de donn√©es
‚îÇ ‚îî‚îÄ‚îÄ paris_meteo_ml_pipeline.py        # Tests unitaires du pipeline de donn√©es
‚îú‚îÄ‚îÄ plugins/ # Plugins Airflow personnalis√©s (ajout√©s au PYTHONPATH)
‚îú‚îÄ‚îÄ tests/
‚îÇ ‚îú‚îÄ‚îÄ dags/
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ full_paris_meteo_ml_forcast_dag.py # Fichier de test pour la structure compl√®te du DAG ML
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ meteo_paris.py # Test ou utilitaire li√© au DAG m√©t√©o
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ weather_utils.py # Fonctions utilitaires partag√©es pour les DAGs m√©t√©o
‚îÇ ‚îú‚îÄ‚îÄ integration/
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ test_dag_structure.py # Test d‚Äôint√©gration (ex√©cut√© avec le marqueur "integration")
‚îÇ ‚îú‚îÄ‚îÄ ml/
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ test_training_pipeline.py # Tests unitaires du pipeline ML
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ test_weather_dags.py # Tests unitaires des DAGs m√©t√©o
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ validate_dags.py # Script de validation syntaxique des DAGs (appel√© dans "Validate DAGs")
‚îÇ ‚îî‚îÄ‚îÄ unit/
‚îÇ ‚îú‚îÄ‚îÄ test_csv_to_s3_upload.py # Test unitaire : upload CSV vers S3
‚îÇ ‚îú‚îÄ‚îÄ test_fetch_weather_data.py # Test unitaire : r√©cup√©ration des donn√©es m√©t√©o
‚îÇ ‚îú‚îÄ‚îÄ test_setup_aws_environment.py # Test unitaire : configuration AWS
‚îÇ ‚îú‚îÄ‚îÄ test_transform_and_append_weather_data.py # Test unitaire : transformation des donn√©es
‚îÇ ‚îî‚îÄ‚îÄ conftest.py # Configuration commune pour pytest
‚îú‚îÄ‚îÄ requirements.txt # D√©pendances Python du projet
‚îú‚îÄ‚îÄ Dockerfile            # Configuration Docker
‚îú‚îÄ‚îÄ .env                  # √† remplir par vos credentials
‚îî‚îÄ‚îÄ Jenkinsfile           # Pipeline CI/CD
```
## üìÅ Sch√©ma Mermaid
```mermaid
graph TD

    subgraph Jenkins["Jenkins (CI/CD)"]
        direction TB
        J_Tests_Units["Tests Units"] --> J_Tests_Int["Tests Int."]
        J_Tests_Int --> J_Trigger_Airflow["Trig. Airflow"]
        J_Trigger_Airflow --> J_Email_Not["Email not."]
    end

    subgraph Airflow["Airflow (Orchestration)"]
        direction LR
        A_DAGs["DAGs"] --> A_Data_Pull["Data Pull"]
        A_Data_Pull --> A_Data_Check["Data Check"]
        A_Data_Check --> A_ML_Training["ML Training"]
        A_ML_Training --> A_Predict["Predict"]
        A_Predict --> A_Email_Not["Email not."]
    end

    subgraph MLflow["MLflow (Model Management)"]
        direction LR
        M_Metrics["Metrics"] --> M_PostgreSQL["PostgreSQL + NEON"]
        M_Artifact_Model["Artifact Model"] --> M_S3_Model["S3 Model"]
    end

    subgraph External["External Services"]
        O_OpenWeatherAPI["OpenWeather API"]
        S_S3_History["S3 Data History"]
        S_S3_Predict["S3 Predict"]
        U_Streamlit["Streamlit App"]
        U_Users["Users"]
    end

    %% Connections
    Jenkins -->|Trigger| Airflow
    Jenkins -->|Notify| TEAM_DATA_J["TEAM DATA"]

    Airflow -->|Pull data from| O_OpenWeatherAPI
    Airflow -->|Store history in| S_S3_History
    Airflow -->|Log metrics to| MLflow
    Airflow -->|Save model to| MLflow
    Airflow -->|Send predictions to| S_S3_Predict
    Airflow -->|Notify| TEAM_DATA_A["TEAM DATA"]

    MLflow -->|Store metrics in| M_PostgreSQL
    MLflow -->|Store model in| M_S3_Model

    S_S3_Predict -->|Feed| U_Streamlit
    U_Streamlit -->|Serve to| U_Users

    %% Styling for grayscale
    classDef gray fill:#f0f0f0,stroke:#666,stroke-width:2px;
    classDef darkGray fill:#d0d0d0,stroke:#444,stroke-width:2px;
    classDef mediumGray fill:#e0e0e0,stroke:#555,stroke-width:2px;

    class Jenkins,Airflow,MLflow,External gray
    class J_Tests_Units,J_Tests_Int,J_Trigger_Airflow,J_Email_Not darkGray
    class A_Data_Pull,A_Data_Check,A_ML_Training,A_Predict,A_Email_Not mediumGray
    class M_Metrics,M_Artifact_Model,M_PostgreSQL,M_S3_Model mediumGray
    class O_OpenWeatherAPI,S_S3_History,S_S3_Predict,U_Streamlit,U_Users darkGray

```

## üìä Donn√©es

Le projet utilise le fichier `data/weather_paris.csv` contenant :
- Temp√©rature, humidit√©, pression
- Conditions m√©t√©orologiques
- Donn√©es historiques de Paris

## üõ† Technologies utilis√©es

- **ML** : scikit-learn, XGBoost, pandas, numpy
- **DataQuality** : Evidently
- **Interface** : Streamlit, folium (cartes)
- **Orchestration** : Apache Airflow
- **MLOps** : MLflow
- **Cloud** : AWS S3, boto3
- **Tests** : pytest, great_expectations
- **DevOps** : Docker, Jenkins, Hugging Face


## üéØ Utilisation


### 1. Collecte de donn√©es pour former le DataSet d'entrainement, via l'API OPENWEATHER
```
dags/meteo_paris.py
```


### 1. Entra√Ænement du mod√®le

```bash
# Version sans MLflow
python app/paris_meteo_no_mlflow.py

# Version avec fusion des donn√©es
python app/paris_meteo_fusion.py
```


### 2. Tests
```bash
# Lancer tous les tests
pytest tests/

# Tests sp√©cifiques
pytest tests/test_paris_meteo_no_mlflow.py
```

### 3. Pipelines Airflow

```bash
cd airflow
docker-compose up -d
```

Acc√©dez √† `http://localhost:8080` pour se connecter √† Airflow ñ£ò :


### 4. Airflow Dags

```
‚îú‚îÄ‚îÄ dags/
‚îÇ ‚îú‚îÄ‚îÄ meteo_paris.py # 1. Collecte des donn√©es m√©t√©o pour former le DATASET, collecte que pour la ville de Paris
‚îÇ ‚îú‚îÄ‚îÄ evidently_datacheck.py # 2. DAG de validation des donn√©es avec Evidently
‚îÇ ‚îú‚îÄ‚îÄ paris_meteo_ml_pipeline.py # 3. DAG pour le pipeline ML (entra√Ænement, etc.)
‚îÇ ‚îî‚îÄ‚îÄ realtime_prediction_forecast.py # 4. DAG pour les pr√©dictions en temps r√©el
```

### 5. Tests Jenkins

Acc√©dez √† `http://localhost:9090` pour se connecter √† Jenkins üéÄ.

```
‚îú‚îÄ‚îÄ dags_ml/ # DAGs Airflow sp√©cifiques au pipeline ML
‚îÇ ‚îú‚îÄ‚îÄ realtime_prediction_forecast.py    # Tests unitaires du pipeline de donn√©es
‚îÇ ‚îî‚îÄ‚îÄ paris_meteo_ml_pipeline.py        # Tests unitaires du pipeline de donn√©es
‚îú‚îÄ‚îÄ tests/
‚îÇ ‚îú‚îÄ‚îÄ dags/
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ full_paris_meteo_ml_forcast_dag.py # Fichier de test pour la structure compl√®te du DAG ML
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ meteo_paris.py # Test ou utilitaire li√© au DAG m√©t√©o
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ weather_utils.py # Fonctions utilitaires partag√©es pour les DAGs m√©t√©o
‚îÇ ‚îú‚îÄ‚îÄ integration/
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ test_dag_structure.py # Test d‚Äôint√©gration (ex√©cut√© avec le marqueur "integration")
‚îÇ ‚îú‚îÄ‚îÄ ml/
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ test_training_pipeline.py # Tests unitaires du pipeline ML
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ test_weather_dags.py # Tests unitaires des DAGs m√©t√©o
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ validate_dags.py # Script de validation syntaxique des DAGs (appel√© dans "Validate DAGs")
‚îÇ ‚îî‚îÄ‚îÄ unit/
‚îÇ ‚îú‚îÄ‚îÄ test_csv_to_s3_upload.py # Test unitaire : upload CSV vers S3
‚îÇ ‚îú‚îÄ‚îÄ test_fetch_weather_data.py # Test unitaire : r√©cup√©ration des donn√©es m√©t√©o
‚îÇ ‚îú‚îÄ‚îÄ test_setup_aws_environment.py # Test unitaire : configuration AWS
‚îÇ ‚îú‚îÄ‚îÄ test_transform_and_append_weather_data.py # Test unitaire : transformation des donn√©es
‚îÇ ‚îî‚îÄ‚îÄ conftest.py # Configuration commune pour pytest
```


## üåü Fonctionnalit√©s

- ‚úÖ Pr√©diction des conditions m√©t√©o (Clear, Clouds, Rain, etc.)
- ‚úÖ Interface web interactive avec carte
- ‚úÖ Pipelines automatis√©s d'entra√Ænement
- ‚úÖ Suivi des exp√©riences ML
- ‚úÖ Tests automatis√©s (Unit et Integration)
- ‚úÖ D√©ploiement Docker
- ‚úÖ Int√©gration CI/CD

## üîß Configuration

1. **Variables d'environnement** : Cr√©er un fichier `.env` avec vos cl√©s API
2. **MLflow** : Configurer l'URI de tracking dans les scripts
3. **AWS** : Configurer les credentials pour S3

> ‚ö†Ô∏è Le test de l‚Äôop√©rateur `S3ToPostgresOperator` a √©t√© **exclu des tests unitaires** car il d√©pend d‚ÄôAirflow et n‚Äôest pas ex√©cutable dans un environnement CI isol√©.

---

## üß™ Tests unitaires

- Couvrent **100 % de la logique m√©tier** (`fetch`, `transform`, `upload S3`)
- Utilisent des **mocks** pour simuler :
  - `requests.get`
  - `airflow.models.Variable.get`
  - `S3Hook`
  - `open()`, `os.path.exists`, etc.
- **Ne d√©pendent pas d‚ÄôAirflow** ‚Üí ex√©cutables sous Jenkins

---

## üõ†Ô∏è Configuration CI (Jenkins)

- Utilise un conteneur Docker `python:3.10-slim`
- Installe les d√©pendances via `requirements.txt`
- Ex√©cute **uniquement les tests unitaires**
- Publie les rapports HTML et JUnit

> ‚úÖ Aucune connexion Airflow, base de donn√©es ou AWS n‚Äôest requise en CI.

---

## üì¶ D√©pendances minimales (`requirements.txt`)

```txt
pandas
requests
pytest
pytest-html
boto3

```

## üìä Gestion des warnings

### pytest.ini
[tool:pytest]
filterwarnings =
    ignore::FutureWarning

## ‚ñ∂Ô∏è Test dans Jenkins
- version de Jenkins : 2.516.3-1
- Blue Ocean : 1.27.23
## ‚ñ∂Ô∏è Lancement de Jenkins
```
docker stop jenkins-blueocean
docker rm jenkins-blueocean
```
> Relancer le container (mapper sur le port 9090 pour √©viter les conflits avec airflow 8080 / Mlflow 8081)

```
docker run --name jenkins-blueocean -d \
  --restart=unless-stopped \
  -p 9090:8080 -p 50000:50000 \
  -v jenkins-data:/var/jenkins_home \
  -v /var/run/docker.sock:/var/run/docker.sock \
  myjenkins-blueocean:2.516.3-1

```
## üì© SMPT de Airflow est configur√© avec GMAIL
- dans l'Admin/Connection : configurer le SMTP avec le port : 587

```
# Utilisation du smtplib.SMTP
with smtplib.SMTP(smtp_host, smtp_port) as server:
            if use_tls:
                server.starttls()
            server.login(conn.login, conn.password)
            server.send_message(msg)
```
## Variable #Airflow

Variable,Description
```
- AWS_ACCESS_KEY_ID,Cl√© AWS pour acc√©der √† S3.
- AWS_SECRET_ACCESS_KEY,Secret AWS.
- BUCKET,Nom du bucket S3 pour les rapports.
- ARTIFACT_STORE_URI,URI du stockage MLflow.
- BACKEND_STORE_URI, du backend MLflow.            
```

## üì© SMPT de Jenkins est configur√© avec GMAIL
- dans l'admin de Jenkins : configurer le SMTP ainsi que l'Extended Email

## D√©clenchement d'Airflow par Jenkins (alternative √† l'API)
- D√©clenchement via CLI- m√™me r√©seau 
- Installation du Client Docker dans Jenkins

## Lancement de MLFLOW LOCAL sur Minikube (si besoin)
- Port Forward : kubectl port-forward svc/mlflow-service 8081:8081


## üìù Licence

Ce projet est sous licence MIT.
