# AIA - BLOC_03 : FRAUD DETECTION ğŸ•µ 

## PrÃ©sentation en ligne de l'intÃ©gralitÃ© du projet

ğŸš€ [Bloc_03 | FRAUD DETECTION | PrÃ©sentation PPT](https://docs.google.com/presentation/d/1EUjt6ZuZBRxjuxuWD4OKV9wgqbWGHm1zGtCbE3KnmMc/edit?usp=sharing) \
ğŸ“ [Bloc_03 | FRAUD DETECTION | Backup sur GitHub](https://github.com/eric-nguyen-jedha/AIA-CERTIF/tree/main/BLOC_03)


# Pipeline de DÃ©tection de Fraude avec Airflow, XGBoost et MLflow

Ce projet implÃ©mente un **pipeline automatisÃ© de dÃ©tection de fraude** en deux Ã©tapes :
1. **VÃ©rification de la qualitÃ© des donnÃ©es** (Drift, tests statistiques) avec Evidently.
2. **EntraÃ®nement d'un modÃ¨le XGBoost** et suivi des expÃ©riences avec MLflow.

Le pipeline est orchestrÃ© avec **Apache Airflow**, et les artefacts sont stockÃ©s sur S3.

---

## ğŸ“Œ Architecture Globale

```mermaid
graph TD
    %% === Sources de donnÃ©es ===
    A[S3 CSV] --> B[Data Pull & Check]
    C[API Transactions] --> D[Predict]

    %% === Nouvelle notification : Data Team ===
    B --> E[Email Alert to Data Team]

    %% === Orchestration Airflow ===
    B --> F[ML Training]
    F --> G[Model Registry]
    D --> H[Email Notification to Anti Fraud Team]

    %% === MLflow ===
    G --> I[Metrics]
    G --> J[Artifact Model]
    I --> K[PostgreSQL NEON]
    J --> L[S3 Model]

    %% === Sauvegarde & Monitoring ===
    D --> M[S3 Predict Backup]
    M --> N[PostgreSQL NEON]
    N --> O[Streamlit Dashboard]
    O --> P[Dashboard for Anti Fraud Team Stakeholder]

    %% === Styles sobres en gris ===
    classDef source fill:#f8f9fa,stroke:#666;
    classDef process fill:#f1f3f5,stroke:#666;
    classDef storage fill:#e9ecef,stroke:#666;
    classDef notification fill:#ffffff,stroke:#666,stroke-dasharray: 3 3;

    class A,C source
    class B,D,F,G,H,E,M,O process
    class K,L,N storage
    class H,E,P notification

```


## ğŸ“‚ Structure du Projet

```
BLOC_03/
â”œâ”€â”€ AIRFLOW/
â”‚ â”œâ”€â”€ config/
â”‚ â”‚ â””â”€â”€ airflow.cfg # Configuration principale dâ€™Airflow
â”‚ â”œâ”€â”€ dags/
â”‚ â”‚ â”œâ”€â”€ fraud_detection_datacheck.py # DAG de validation des donnÃ©es (prÃ©-processing)
â”‚ â”‚ â”œâ”€â”€ fraud_detection_ml.py # DAG dâ€™entraÃ®nement du modÃ¨le de dÃ©tection de fraude
â”‚ â”‚ â”œâ”€â”€ fraud_detection_predict.py # DAG de prÃ©diction en production
â”‚ â”‚ â””â”€â”€ fraud_detection_recap24h.py # DAG de rÃ©sumÃ© journalier (rapport, monitoring)
â”‚ â”œâ”€â”€ data/
â”‚ â”‚ â”œâ”€â”€ current_transactions_raw.csv # DonnÃ©es brutes des transactions
â”‚ â”‚ â”œâ”€â”€ current_transactions_clean.csv # DonnÃ©es nettoyÃ©es aprÃ¨s preprocessing
â”‚ â”‚ â”œâ”€â”€ fraud_detection_on_going.csv # DonnÃ©es en cours de traitement / surveillance
â”‚ â”‚ â””â”€â”€ predictions.csv # RÃ©sultats des prÃ©dictions gÃ©nÃ©rÃ©es
â”‚ â”œâ”€â”€ docker-compose.yaml # Orchestration Docker pour Airflow
â”‚ â””â”€â”€ Dockerfile # Image Docker pour lâ€™environnement Airflow
â”œâ”€â”€ plugins/
â”‚ â””â”€â”€ s3_to_postgres.py # Plugin Airflow personnalisÃ© (transfert S3 â†’ PostgreSQL)
â”œâ”€â”€ requirements.txt # DÃ©pendances Python globales du projet
â”œâ”€â”€ eda_fraud.ipynb # Notebook dâ€™analyse exploratoire des donnÃ©es (EDA) : FraudTest.csv
â”œâ”€â”€ MLFLOW/
â”‚ â”œâ”€â”€ Dockerfile # Image Docker pour lâ€™environnement MLflow
â”‚ â”œâ”€â”€ README.md # Documentation du module MLflow
â”‚ â”œâ”€â”€ requirements.txt # DÃ©pendances spÃ©cifiques Ã  MLflow
â”‚ â””â”€â”€ pairplot.png # Visualisation graphique (ex: scatter plot ou heatmap)
â”œâ”€â”€ README.md # Documentation gÃ©nÃ©rale du projet BLOC_03
â”œâ”€â”€ STREAMLIT/
â”‚ â”œâ”€â”€ app.py # app_streamlit.py # Application Streamlit pour visualisation des rÃ©sultats
â”‚ â”œâ”€â”€ Dockerfile # Image Docker pour le dÃ©ploiement de lâ€™app Streamlit
â”‚ â”œâ”€â”€ README.md # Documentation du module Streamlit
â”‚ â””â”€â”€ requirements.txt # DÃ©pendances spÃ©cifiques Ã  lâ€™app Streamlit

```

AccÃ©dez Ã  `http://localhost:8080` pour se connecter Ã  Airflow ğ–£˜ :

## 1ï¸âƒ£ DAG fraud_detection_01_evidently_data_quality

Objectif : VÃ©rifier la qualitÃ© des donnÃ©es avant l'entraÃ®nement.
FonctionnalitÃ©s :

- download_fraud_csv : TÃ©lÃ©charge le dataset fraudTest.csv depuis une URL.
- evidently_check : GÃ©nÃ¨re un rapport de drift (visuel) et une test suite (textuelle) avec Evidently.
- upload_reports_to_s3 : Sauvegarde les rapports en local et sur S3.
- send_evidently_report_email : Envoie un email de rÃ©sumÃ© avec les liens vers les rapports.
- trigger_xgboost_dag : DÃ©clenche le DAG suivant (fraud_detection_xgboost_dag) en passant le chemin du fichier CSV.

## 2ï¸âƒ£ DAG fraud_detection_02_xgboost_dag
Objectif : EntraÃ®ner un modÃ¨le XGBoost pour dÃ©tecter les fraudes.
FonctionnalitÃ©s :

- load_csv : RÃ©cupÃ¨re le chemin du fichier CSV passÃ© par le DAG prÃ©cÃ©dent (dag_run.conf).
- clean_data : Nettoie les donnÃ©es (feature engineering, encodage, etc.).
- train_mlflow : EntraÃ®ne un modÃ¨le XGBoost avec suivi des mÃ©triques via MLflow. Sauvegarde la matrice de confusion et log le modÃ¨le.

## 3ï¸âƒ£ DAG fraud_detection_03_prediction_api
Objectif : Faire une prÃ©diction en temps rÃ©el d'une Fraude .
FonctionnalitÃ©s :

- fetch_transactions : RÃ©cupÃ¨re la transaction qui vient de l'API.
- preprocess_data : Nettoie les donnÃ©es et les rend conforme au modÃ¨le d'entrainement
- predict_and_save : Faire une prÃ©diction avec le code Predict de MLFLOW et sauvegarder le rÃ©sultat dans un CSV mais aussi dans la Base Neon BD (PostgreSQL)
- upload_and_alert : Upload les rÃ©sultats dans un fichier CSV et envoie une notification Ã  l'Ã©quipe DATA

## 4ï¸âƒ£ DAG fraud_detection_04_recap_email

- send_fraud_recap_email : Se connecte Ã  la base de donnÃ©e PosteGreSQL, calcule les stats des derniÃ¨res 24H et envoie un rÃ©sumÃ© ainsi que le lien pour se connecter au Dashboard


## Variable #Airflow

Variable,Description
- AWS_ACCESS_KEY_ID,ClÃ© AWS pour accÃ©der Ã  S3.
- AWS_SECRET_ACCESS_KEY,Secret AWS.
- BUCKET,Nom du bucket S3 pour les rapports.
- ARTIFACT_STORE_URI,URI du stockage MLflow.
- BACKEND_STORE_URI_FP,URI du backend MLflow.

## ğŸ“© SMPT de Airflow est configurÃ© avec GMAIL
- dans l'Admin/Connection : configurer le SMTP avec le port : 587

```
# Utilisation du smtplib.SMTP
with smtplib.SMTP(smtp_host, smtp_port) as server:
            if use_tls:
                server.starttls()
            server.login(conn.login, conn.password)
            server.send_message(msg)
```            

## ğŸ”§ Comment Lancer le Pipeline ?
1. DÃ©ployer les DAGs

Copier les fichiers .py dans le dossier dags/ d'Airflow.
Activer les DAGs dans l'UI Airflow.

2. ExÃ©cuter manuellement (optionnel)

Dans l'UI Airflow, cliquer sur Trigger DAG pour evidently_data_quality_fraud.
Le DAG XGBoost sera dÃ©clenchÃ© automatiquement.

3. VÃ©rifier les rÃ©sultats

Rapports : Voir les emails envoyÃ©s ou les fichiers dans le bucket S3.
ModÃ¨le : Consulter l'expÃ©rience MLflow Ã  l'URL configurÃ©e.


âš ï¸ Points d'Attention

- DÃ©pendances : VÃ©rifier que toutes les librairies sont installÃ©es dans l'environnement Airflow.
- Permissions S3 : Le rÃ´le IAM doit avoir les droits s3:PutObject et s3:GetObject.
- MLflow : L'URI du tracking doit Ãªtre accessible depuis Airflow. MLFLOW est installÃ© sur Hugging Face dans un Docker 
- Chemin des fichiers : Le dossier /opt/airflow/data doit Ãªtre montÃ© et accessible en Ã©criture.